# ğŸš€ Get Your Hands Dirty - Data Engineering

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![SQL](https://img.shields.io/badge/SQL-PostgreSQL%20%7C%20MySQL-lightgrey.svg)](https://www.postgresql.org/)
[![Apache Spark](https://img.shields.io/badge/Apache%20Spark-3.0+-orange.svg)](https://spark.apache.org/)

> **A comprehensive hands-on repository for mastering Data Engineering technologies through practical examples and real-world problems.**

Welcome to the ultimate Data Engineering learning repository! This project contains hands-on labs, examples, and solutions covering all major DE technologies and tools used in modern data pipelines.

## ğŸ“‹ Table of Contents

- [ğŸ¯ Overview](#-overview)
- [ğŸ› ï¸ Technologies Covered](#ï¸-technologies-covered)
- [ğŸ“ Repository Structure](#-repository-structure)
- [ğŸš€ Quick Start](#-quick-start)
- [ğŸ’¡ Featured Projects](#-featured-projects)
- [ğŸ“š Learning Path](#-learning-path)
- [ğŸ”§ Setup Instructions](#-setup-instructions)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“„ License](#-license)

## ğŸ¯ Overview

This repository is designed for **Data Engineers**, **Analytics Engineers**, and **Software Engineers** who want to:

- ğŸ“ˆ **Level up** their data engineering skills
- ğŸ”¨ **Practice** with real-world scenarios and problems
- ğŸ§ª **Experiment** with different technologies and approaches
- ğŸ’¼ **Prepare** for technical interviews (Google, Meta, Netflix, etc.)
- ğŸ“ **Learn** industry best practices and optimization techniques

## ğŸ› ï¸ Technologies Covered

### **Core Data Processing**
- ![SQL](https://img.shields.io/badge/SQL-Advanced-blue) **SQL** - Complex queries, optimization, window functions
- ![Pandas](https://img.shields.io/badge/Pandas-DataFrame%20Mastery-green) **Pandas** - Data manipulation, performance optimization
- ![Apache Spark](https://img.shields.io/badge/Apache%20Spark-PySpark%20%7C%20Scala-orange) **Apache Spark** - Distributed computing, RDDs, DataFrames
- ![Apache Flink](https://img.shields.io/badge/Apache%20Flink-Stream%20Processing-red) **Apache Flink** - Real-time stream processing

### **Data Pipeline & Orchestration**
- ![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-Workflow%20Orchestration-lightblue) **Apache Airflow** - DAGs, scheduling, monitoring
- ![Apache Flume](https://img.shields.io/badge/Apache%20Flume-Data%20Ingestion-yellow) **Apache Flume** - Log collection and aggregation
- ![Google Dataflow](https://img.shields.io/badge/Google%20Dataflow-Beam%20Pipelines-blue) **Google Dataflow** - Serverless data processing

### **Query Engines & Analytics**
- ![Presto](https://img.shields.io/badge/Presto-Distributed%20SQL-purple) **Presto/Trino** - Interactive analytics at scale
- ![Apache Drill](https://img.shields.io/badge/Apache%20Drill-Schema--free%20SQL-brown) **Apache Drill** - Schema-free SQL queries
- ![ClickHouse](https://img.shields.io/badge/ClickHouse-OLAP%20Database-lightgreen) **ClickHouse** - Columnar analytics database

### **Storage & Formats**
- ![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-Event%20Streaming-black) **Apache Kafka** - Event streaming platform
- ![Apache Hive](https://img.shields.io/badge/Apache%20Hive-Data%20Warehousing-orange) **Apache Hive** - Data warehouse software
- ![Delta Lake](https://img.shields.io/badge/Delta%20Lake-ACID%20Transactions-blue) **Delta Lake** - ACID transactions for data lakes
- ![Apache Parquet](https://img.shields.io/badge/Parquet-Columnar%20Storage-green) **Parquet** - Columnar storage format

### **Cloud Platforms**
- ![AWS](https://img.shields.io/badge/AWS-S3%20%7C%20EMR%20%7C%20Glue-orange) **AWS** - S3, EMR, Glue, Redshift
- ![Google Cloud](https://img.shields.io/badge/GCP-BigQuery%20%7C%20Dataflow-blue) **Google Cloud** - BigQuery, Dataflow, Pub/Sub
- ![Azure](https://img.shields.io/badge/Azure-Data%20Factory%20%7C%20Synapse-lightblue) **Azure** - Data Factory, Synapse Analytics

## ğŸ“ Repository Structure

```
Get-Your-Hands-Dirty-DE/
â”œâ”€â”€ ğŸ“Š sql/                          # SQL Labs & Advanced Queries
â”‚   â”œâ”€â”€ basics/                      # Fundamentals & syntax
â”‚   â”œâ”€â”€ advanced/                    # Window functions, CTEs, optimization
â”‚   â”œâ”€â”€ interview-problems/          # LeetCode-style SQL problems
â”‚   â””â”€â”€ real-world-scenarios/        # Production-like queries
â”‚
â”œâ”€â”€ ğŸ¼ pandas/                       # Pandas Data Manipulation
â”‚   â”œâ”€â”€ performance-optimization/    # Vectorization, memory management
â”‚   â”œâ”€â”€ data-cleaning/              # Missing data, duplicates, transformations
â”‚   â”œâ”€â”€ merge-strategies/           # Joins, concatenation, comparison
â”‚   â””â”€â”€ time-series/                # DateTime operations, resampling
â”‚
â”œâ”€â”€ âš¡ spark/                        # Apache Spark Projects
â”‚   â”œâ”€â”€ pyspark/                    # Python Spark examples
â”‚   â”œâ”€â”€ scala-spark/                # Scala Spark implementations
â”‚   â”œâ”€â”€ streaming/                  # Spark Streaming applications
â”‚   â””â”€â”€ optimization/               # Performance tuning, caching
â”‚
â”œâ”€â”€ ğŸŒŠ flink/                        # Apache Flink Stream Processing
â”‚   â”œâ”€â”€ event-time-processing/      # Watermarks, windowing
â”‚   â”œâ”€â”€ state-management/           # Checkpointing, savepoints
â”‚   â””â”€â”€ connectors/                 # Kafka, databases, filesystems
â”‚
â”œâ”€â”€ ğŸ“ˆ dataflow/                     # Google Dataflow (Apache Beam)
â”‚   â”œâ”€â”€ batch-pipelines/            # Batch processing examples
â”‚   â”œâ”€â”€ streaming-pipelines/        # Real-time data processing
â”‚   â””â”€â”€ templates/                  # Reusable pipeline templates
â”‚
â”œâ”€â”€ ğŸ” presto/                       # Presto/Trino Query Engine
â”‚   â”œâ”€â”€ federation/                 # Cross-database queries
â”‚   â”œâ”€â”€ performance-tuning/         # Query optimization
â”‚   â””â”€â”€ custom-functions/           # UDFs and plugins
â”‚
â”œâ”€â”€ ğŸ“¥ flume/                        # Apache Flume Data Ingestion
â”‚   â”œâ”€â”€ configurations/             # Agent configurations
â”‚   â”œâ”€â”€ custom-sources-sinks/       # Custom components
â”‚   â””â”€â”€ monitoring/                 # Performance monitoring
â”‚
â”œâ”€â”€ ğŸ¯ projects/                     # End-to-End Data Engineering Projects
â”‚   â”œâ”€â”€ recommendation-system/      # ML-powered recommendations
â”‚   â”œâ”€â”€ real-time-analytics/        # Streaming analytics dashboard
â”‚   â”œâ”€â”€ data-lake-architecture/     # Modern data lake implementation
â”‚   â””â”€â”€ etl-pipelines/              # Production ETL workflows
â”‚
â”œâ”€â”€ ğŸ§ª experiments/                  # Technology Comparisons & Benchmarks
â”‚   â”œâ”€â”€ pandas-vs-polars/           # Performance comparisons
â”‚   â”œâ”€â”€ sql-optimization/           # Query performance analysis
â”‚   â””â”€â”€ storage-formats/            # Parquet vs ORC vs Delta
â”‚
â”œâ”€â”€ ğŸ“‹ interview-prep/               # Technical Interview Preparation
â”‚   â”œâ”€â”€ coding-problems/            # Data structure & algorithm problems
â”‚   â”œâ”€â”€ system-design/              # Scalable system architectures
â”‚   â””â”€â”€ case-studies/               # Real interview questions
â”‚
â””â”€â”€ ğŸ“š docs/                         # Documentation & Guides
    â”œâ”€â”€ setup-guides/               # Environment setup instructions
    â”œâ”€â”€ best-practices/             # Industry standards & patterns
    â””â”€â”€ troubleshooting/            # Common issues & solutions
```

## ğŸš€ Quick Start

### Prerequisites
```bash
# Python 3.8+
python --version

# Java 8+ (for Spark, Flink)
java -version

# Docker (for containerized services)
docker --version
```

### Installation
```bash
# Clone the repository
git clone https://github.com/koustreak/Get-Your-Hands-Dirty-DE.git
cd Get-Your-Hands-Dirty-DE

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Verify installation
python -c "import pandas, pyspark; print('âœ… Environment ready!')"
```

## ğŸ’¡ Featured Projects

### ğŸ”¥ Facebook Page Recommendation System
**Technologies**: SQL, Pandas, Performance Optimization

A comprehensive implementation of a social media recommendation engine with multiple optimization strategies:

```sql
-- ğŸ† Most Optimized Solution (EXISTS vs JOIN vs IN comparison)
SELECT fp.*
FROM facebook_posts fp
WHERE EXISTS (
    SELECT 1 FROM facebook_reactions fr 
    WHERE fr.post_id = fp.post_id AND fr.reaction = 'heart'
);
```

**Key Features**:
- âš¡ **5+ different implementation strategies** (SQL, Pandas, Polars)
- ğŸ“Š **Performance benchmarking** and analysis
- ğŸ¯ **Google/Meta interview-ready** solutions
- ğŸ“ˆ **Scalability considerations** for production systems

### ğŸŒŠ Real-Time Analytics Pipeline
**Technologies**: Kafka, Flink, ClickHouse, Grafana

End-to-end streaming analytics platform processing millions of events per second.

### ğŸ—ï¸ Modern Data Lake Architecture
**Technologies**: Spark, Delta Lake, Apache Iceberg, AWS S3

Production-ready data lake implementation with ACID transactions and time travel capabilities.

## ğŸ“š Learning Path

### ğŸ¯ **Beginner Track** (4-6 weeks)
1. **SQL Fundamentals** â†’ Basic queries, joins, aggregations
2. **Pandas Basics** â†’ DataFrames, data cleaning, basic operations
3. **Introduction to Spark** â†’ RDDs, basic transformations
4. **Simple ETL Pipelines** â†’ Extract, transform, load workflows

### ğŸš€ **Intermediate Track** (6-8 weeks)
1. **Advanced SQL** â†’ Window functions, CTEs, optimization
2. **Pandas Performance** â†’ Vectorization, memory optimization
3. **Spark Deep Dive** â†’ DataFrames, Spark SQL, performance tuning
4. **Stream Processing** â†’ Kafka, basic Flink applications

### ğŸ† **Advanced Track** (8-12 weeks)
1. **Query Optimization** â†’ Execution plans, indexing strategies
2. **Distributed Systems** â†’ Partitioning, sharding, consistency
3. **Real-Time Processing** â†’ Complex event processing, windowing
4. **Production Systems** â†’ Monitoring, alerting, disaster recovery

### ğŸ“ **Expert Track** (Ongoing)
1. **System Design** â†’ Scalable architectures, trade-offs
2. **Performance Engineering** â†’ Profiling, bottleneck analysis
3. **Custom Solutions** â†’ Building frameworks, contributing to OSS
4. **Leadership & Mentoring** â†’ Technical leadership, code reviews

## ğŸ”§ Setup Instructions

### Local Development Environment

<details>
<summary><b>ğŸ³ Docker Setup (Recommended)</b></summary>

```bash
# Start all services
docker-compose up -d

# Verify services
docker-compose ps

# Access Jupyter Lab
open http://localhost:8888

# Access Spark UI
open http://localhost:4040
```
</details>

<details>
<summary><b>ğŸ› ï¸ Manual Setup</b></summary>

```bash
# Install Apache Spark
wget https://downloads.apache.org/spark/spark-3.4.0/spark-3.4.0-bin-hadoop3.tgz
tar -xzf spark-3.4.0-bin-hadoop3.tgz
export SPARK_HOME=$PWD/spark-3.4.0-bin-hadoop3

# Install Apache Flink
wget https://downloads.apache.org/flink/flink-1.17.0/flink-1.17.0-bin-scala_2.12.tgz
tar -xzf flink-1.17.0-bin-scala_2.12.tgz
export FLINK_HOME=$PWD/flink-1.17.0

# Verify installations
$SPARK_HOME/bin/spark-submit --version
$FLINK_HOME/bin/flink --version
```
</details>

### Cloud Platform Setup

<details>
<summary><b>â˜ï¸ AWS Setup</b></summary>

```bash
# Configure AWS CLI
aws configure

# Create S3 bucket for data storage
aws s3 mb s3://your-de-hands-on-bucket

# Setup EMR cluster (optional)
aws emr create-cluster --name "DE-HandsOn-Cluster" \
  --release-label emr-6.9.0 \
  --instance-type m5.xlarge \
  --instance-count 3
```
</details>

## ğŸ¤ Contributing

We welcome contributions from the community! Here's how you can help:

### ğŸ¯ **Ways to Contribute**
- ğŸ“ **Add new examples** in any DE technology
- ğŸ› **Fix bugs** or improve existing code
- ğŸ“š **Improve documentation** and tutorials
- ğŸ§ª **Add performance benchmarks** and comparisons
- ğŸ’¡ **Suggest new project ideas** or improvements

### ğŸ”„ **Contribution Process**
1. **Fork** the repository
2. **Create** a feature branch: `git checkout -b feature/amazing-feature`
3. **Commit** your changes: `git commit -m 'Add amazing feature'`
4. **Push** to the branch: `git push origin feature/amazing-feature`
5. **Open** a Pull Request

### ğŸ“‹ **Contribution Guidelines**
- âœ… Follow existing code style and patterns
- âœ… Add comprehensive documentation and comments
- âœ… Include performance benchmarks where applicable
- âœ… Add unit tests for new functionality
- âœ… Update README if adding new technologies

## ğŸ“Š Performance Benchmarks

| Technology | Dataset Size | Processing Time | Memory Usage | Scalability |
|------------|-------------|----------------|--------------|-------------|
| **Pandas** | 1GB | 2.3s | 8GB | Single Machine |
| **Polars** | 1GB | 0.8s | 4GB | Single Machine |
| **Spark** | 100GB | 45s | 16GB | Multi-Node |
| **Flink** | Streaming | Real-time | 8GB | Multi-Node |

## ğŸ† Success Stories

> *"This repository helped me land a Data Engineer role at Google! The SQL optimization techniques and system design examples were exactly what I needed."* - **Sarah K., Google DE**

> *"The Spark performance tuning section saved our production pipeline. Reduced processing time from 4 hours to 45 minutes!"* - **Mike R., Netflix**

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸŒŸ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=koustreak/Get-Your-Hands-Dirty-DE&type=Date)](https://star-history.com/koustreak/Get-Your-Hands-Dirty-DE)

---

<div align="center">

### ğŸš€ Ready to Level Up Your Data Engineering Skills?

**[â­ Star this repository](https://github.com/koustreak/Get-Your-Hands-Dirty-DE)** â€¢ **[ğŸ´ Fork and contribute](https://github.com/koustreak/Get-Your-Hands-Dirty-DE/fork)** â€¢ **[ğŸ“– Read the docs](./docs/)**

**Built with â¤ï¸ by [Koushik](https://github.com/koustreak) and the Data Engineering Community**

</div>
